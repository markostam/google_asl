{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1.2.1', '0.5.1')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import random\n",
    "import taglib\n",
    "import jams\n",
    "import muda\n",
    "import time\n",
    "print(tf.__version__, librosa.__version__)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Pipeline for Second Hand Songset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TRAIN_FOLDER = \"/Users/markostamenovic/code/shs/shs_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def txt_to_cliques(shs_loc):\n",
    "    '''\n",
    "    reads a textfile of song cliques in shs\n",
    "    creates a dictionary out of second hand songset 'cliques'\n",
    "    or groups of cover songs and returns the dict of cliques\n",
    "    based on their msd id\n",
    "    '''\n",
    "    shs = list(open(shs_loc))\n",
    "    shs = shs[14:]\n",
    "    cliques = {}\n",
    "    for ent in shs:\n",
    "        ent = ent.replace('\\n','')\n",
    "        if ent[0] == '%':\n",
    "            tempKey = ent.lower()\n",
    "            cliques[tempKey] = []\n",
    "        else:\n",
    "            cliques[tempKey].append(ent.split(\"<SEP>\")[0]+'.mp3')\n",
    "    return cliques\n",
    "cliques = txt_to_cliques(os.path.join(TRAIN_FOLDER, \"shs_dataset_train.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_labels(cliques):\n",
    "    # get and flatten all combination of coversongs\n",
    "    positive_examples = (list(itertools.combinations(val,2)) for key,val in cliques.items())\n",
    "    positive_examples = [i for j in positive_examples for i in j]\n",
    "    positive_len_og = len(positive_examples)\n",
    "    positive_labels = [[0,1] for _ in positive_examples]\n",
    "    # generate negative examples of an equivalent length to the positive examples list\n",
    "    song_from_each_clique = (random.choice(val) for key,val in cliques.items())\n",
    "    negative_examples = itertools.combinations(song_from_each_clique,2)\n",
    "    negative_examples = list(itertools.islice(negative_examples, positive_len_og))\n",
    "    negative_labels = [[1,0] for _ in negative_examples]\n",
    "    # \n",
    "    x = positive_examples + negative_examples\n",
    "    y = positive_labels + negative_labels\n",
    "    return zip(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def join_files_to_path(targets_labels):\n",
    "    return [(map(lambda x: os.path.join(TRAIN_FOLDER, x), target), label) for target,label in targets_labels] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "corrupted_folder = \"/Users/markostamenovic/code/shs/shs_train/small_size_mp3s\"\n",
    "\n",
    "def prune_corrupted_files(targets_labels):\n",
    "    corrupted_folder = os.path.join(TRAIN_FOLDER, \"small_size_mp3s\")\n",
    "    pruned = []\n",
    "    corrupted = [i for i in os.listdir(corrupted_folder) if i.endswith(\"mp3\")]\n",
    "    clean = [i for i in os.listdir(TRAIN_FOLDER) if i.endswith(\"mp3\")]\n",
    "    \n",
    "    for target, label in targets_labels:\n",
    "        if target[0] in corrupted or target[1] in corrupted:\n",
    "            pass\n",
    "        if target[0] not in clean or target[1] not in clean:\n",
    "            pass\n",
    "        else:\n",
    "            pruned.append((target,label))\n",
    "    return pruned\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_one_file(file_path, _duration, augmentation = True):\n",
    "#     1 loop, best of 3: 578 ms per loop\n",
    "#     t0 = time.time()\n",
    "    file_path = file_path[0]\n",
    "    stretch_scale = .05\n",
    "#     duration = np.multiply( _duration, ( np.add( np.multiply( stretch_scale, 2), 1))) # we do this to pad for potential stretch\n",
    "    f_len = np.float32(taglib.File(file_path).length)\n",
    "    # require(duration >= f_len) check that duration is below length\n",
    "    start_bound = np.subtract(f_len, _duration)\n",
    "    start = np.float(np.random.randint(0,start_bound))\n",
    "    y, sr = librosa.core.load(path = file_path,\n",
    "                              offset = start,\n",
    "                              duration = _duration,  \n",
    "                              res_type='kaiser_fast')\n",
    "    ''' deformation pipeline'''\n",
    "    if augmentation:\n",
    "        jam = jams.JAMS()\n",
    "        jam.file_metadata.duration = librosa.get_duration(y=y, sr=sr)\n",
    "        jam.file_metadata.identifiers = os.path.basename(file_path)\n",
    "        j_orig = muda.jam_pack(jam, _audio=dict(y=y, sr=sr))\n",
    "        pitch_shift = muda.deformers.RandomPitchShift(n_samples=1, mean=0.0, sigma=1.0)\n",
    "        time_stretch = muda.deformers.RandomTimeStretch(n_samples=1, location=0.0, scale=stretch_scale)\n",
    "    #     noise = muda.deformers.BackgroundNoise(n_samples=1)\n",
    "    #     drc = muda.deformers.DynamicRangeCompression(preset=muda.deformers.PRESETS.keys())\n",
    "    #     drc = muda.deformers.PRESETS.keys()\n",
    "    #     drc.append(False)\n",
    "    #     drc = random.choice(drc)\n",
    "    #     if drc:\n",
    "    #         compress = muda.deformers.DynamicRangeCompression(preset=drc)\n",
    "    #     else:\n",
    "    #         compress = time_stretch\n",
    "        pipeline = muda.Pipeline(steps=[('pitch_shift', pitch_shift),\n",
    "                                        ('time_stretch', time_stretch)])\n",
    "        out = list(pipeline.transform(j_orig))[0]\n",
    "        y_t, sr_t = out.sandbox.muda._audio.values()\n",
    "        '''zero pad for deformation length change'''\n",
    "    else:\n",
    "        y_t = y\n",
    "        sr_t = sr\n",
    "        \n",
    "    required_samples = _duration*sr_t\n",
    "    deformed_samples = y_t.shape[0]\n",
    "    sample_diff = np.abs(np.subtract(deformed_samples,required_samples))\n",
    "\n",
    "    if deformed_samples > required_samples:\n",
    "        y_t = y_t[:required_samples]\n",
    "    else:\n",
    "        y_t = np.lib.pad(y_t, (0,sample_diff), 'constant', constant_values=(0, 0))\n",
    "    \n",
    "    '''get cqt'''\n",
    "    cqt = librosa.core.cqt(y_t, sr=sr_t,\n",
    "                           hop_length=1024, \n",
    "                           fmin=None, n_bins=84, \n",
    "                           bins_per_octave=12, \n",
    "                           tuning=0.0, \n",
    "                           filter_scale=1, \n",
    "                           norm=1, \n",
    "                           sparsity=0.01, \n",
    "                           window='hann', \n",
    "                           scale=True)\n",
    "    \n",
    "#     elapsed = time.time() - t0\n",
    "#     print(\"elapsed = {}\").format(elapsed)\n",
    "    return np.abs(cqt).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 4))\n",
    "# librosa.display.specshow(librosa.power_to_db(S,ref=np.max),\n",
    "#                           y_axis='mel', fmax=11025,\n",
    "#                           x_axis='time')\n",
    "# plt.colorbar(format='%+2.0f dB')\n",
    "# plt.title('Mel spectrogram')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "targets_labels = join_files_to_path(prune_corrupted_files(get_labels(cliques)))\n",
    "targets_t_0 = tf.cast(tf.expand_dims(tf.convert_to_tensor(np.array(targets_labels)[:,0][:,0]),1), tf.string)\n",
    "targets_t_1 = tf.cast(tf.expand_dims(tf.convert_to_tensor(np.array(targets_labels)[:,0][:,1]),1), tf.string)\n",
    "labels_t = tf.convert_to_tensor(np.array(targets_labels)[:,1].astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f0, f1, labels = tf.train.slice_input_producer(\n",
    "    [targets_t_0, targets_t_1, labels_t], \n",
    "    num_epochs=None, \n",
    "    shuffle=True, \n",
    "    seed=None, \n",
    "    capacity=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_slices(filename, sr=22050, hop_length=1024, duration=15, file_read_dur=29):\n",
    "    frames_pre_sec = int(sr/hop_length)\n",
    "    slice_size = duration*(frames_pre_sec)\n",
    "#     print(slice_size)\n",
    "    spec_1_t = tf.py_func(process_one_file, [filename, file_read_dur], tf.float32)\n",
    "#     _, ncols = spec_1_t.shape.as_list()\n",
    "    ncols=625\n",
    "    spec_1_t.set_shape([84, 625])\n",
    "    at_win = tf.map_fn(lambda i: spec_1_t[:,i:i+slice_size], tf.range(ncols - slice_size+1), dtype=tf.float32)\n",
    "    at_shuff = tf.random_shuffle(at_win)\n",
    "    return at_shuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "specs = tf.stack([get_slices(f0), get_slices(f1)],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_j = tf.train.shuffle_batch_join(\n",
    "    \n",
    "    [[specs]]*8,                           # this many parallel\n",
    "    batch_size = 16,                       # dequeue this many\n",
    "    capacity = 8192,                       # this is the queue capacity\n",
    "    min_after_dequeue = 7192,              # minimum after dq\n",
    "    enqueue_many = True,                   # push multiple examples to queue for each input producer\n",
    "    shapes = tf.TensorShape([2, 84, 315])  # shape of the non-batch dimension\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch = tf.train.shuffle_batch(\n",
    "    \n",
    "    [specs],                            \n",
    "    batch_size = 16,                       # dequeue this many\n",
    "    capacity = 8192,                       # this is the queue capacity\n",
    "    min_after_dequeue = 7192,              # minimum after dq\n",
    "    num_threads=8,\n",
    "    enqueue_many = True,                   # push multiple examples to queue for each input producer \n",
    "    shapes = tf.TensorShape([2, 84, 315])  # shape of the non-batch dimension\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, exceptions.ValueError: low >= high\n",
      "\t [[Node: PyFunc_1 = PyFunc[Tin=[DT_STRING, DT_INT32], Tout=[DT_FLOAT], token=\"pyfunc_1\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_producer/Gather_1, PyFunc_1/input_1)]]\n",
      "(16, 2, 84, 315)\n",
      "steps per sec = 0.0163773144732\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    sps = []\n",
    "    for _ in range(100):\n",
    "        t0 = time.time()\n",
    "        a = sess.run(batch)\n",
    "        print(a.shape)\n",
    "        elapsed = time.time() - t0\n",
    "        steps_sec = 1/elapsed\n",
    "        print(\"steps per sec = {}\").format(steps_sec)\n",
    "        sps.append(steps_sec)\n",
    "    print(\"mean steps per sec = {}\").format(np.mean(sps[4:])) #drop the first few steps bc thats filling queue\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
