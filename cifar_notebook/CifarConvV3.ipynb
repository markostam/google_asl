{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Config:\n",
    "\n",
    "raw_img_dir = \"./data/cifar-10-batches-bin/\"\n",
    "train_files = [\"data_batch_1.bin\", \"data_batch_2.bin\", \"data_batch_3.bin\", \"data_batch_4.bin\"]\n",
    "valid_files = [\"data_batch_5.bin\"]\n",
    "test_files = [\"test_batch.bin\"]\n",
    "\n",
    "MODEL_DIR = \"./models/\"\n",
    "MODEL_NAME = \"conv1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Input functions:\n",
    "\n",
    "\n",
    "IMAGE_SIZE = 32\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000 #50000\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000 #10000\n",
    "\n",
    "def read_cifar10(filename_queue):\n",
    "\n",
    "    class CIFAR10Record(object):\n",
    "        pass\n",
    "    result = CIFAR10Record()\n",
    "    \n",
    "    label_bytes = 1  # 2 for CIFAR-100\n",
    "    result.height = IMAGE_SIZE\n",
    "    result.width = IMAGE_SIZE\n",
    "    result.depth = 3\n",
    "    image_bytes = result.height * result.width * result.depth\n",
    "    record_bytes = label_bytes + image_bytes\n",
    "\n",
    "    reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)\n",
    "    result.key, value = reader.read(filename_queue)\n",
    "    record_bytes = tf.decode_raw(value, tf.uint8)\n",
    "    result.label = tf.cast(tf.strided_slice(record_bytes, [0], [label_bytes]), tf.int32)\n",
    "    depth_major = tf.reshape(\n",
    "      tf.strided_slice(record_bytes, [label_bytes],\n",
    "                       [label_bytes + image_bytes]),\n",
    "      [result.depth, result.height, result.width])\n",
    "    result.uint8image = tf.transpose(depth_major, [1, 2, 0])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def _generate_image_and_label_batch(image, label, min_queue_examples, batch_size, shuffle):\n",
    "    num_preprocess_threads = 16\n",
    "    if shuffle:\n",
    "        images, label_batch = tf.train.shuffle_batch(\n",
    "            [image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads,\n",
    "            capacity=min_queue_examples + num_preprocess_threads * batch_size,\n",
    "            min_after_dequeue=min_queue_examples)\n",
    "    else:\n",
    "        images, label_batch = tf.train.batch(\n",
    "            [image, label],\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_preprocess_threads,\n",
    "            capacity=min_queue_examples + num_preprocess_threads * batch_size)\n",
    "\n",
    "    tf.summary.image('images', images)\n",
    "    return images, tf.reshape(label_batch, [batch_size])\n",
    "\n",
    "'''\n",
    "Data Augmentation Pipeline\n",
    "'''\n",
    "\n",
    "def distorted_inputs(data_dir, batch_size):\n",
    "\n",
    "    with tf.name_scope(\"Input\"):\n",
    "\n",
    "        filenames = [os.path.join(data_dir,fn) for fn in train_files]\n",
    "        filename_queue = tf.train.string_input_producer(filenames, capacity = batch_size*16)\n",
    "        read_input = read_cifar10(filename_queue)\n",
    "        reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n",
    "\n",
    "        height = IMAGE_SIZE\n",
    "        width = IMAGE_SIZE\n",
    "\n",
    "        distorted_image = tf.random_crop(reshaped_image, [height, width, 3])\n",
    "        distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "        distorted_image = tf.image.random_brightness(distorted_image,\n",
    "                                                   max_delta=63)\n",
    "        distorted_image = tf.image.random_contrast(distorted_image,\n",
    "                                                 lower=0.2, upper=1.8)\n",
    "        # image whitening\n",
    "        float_image = tf.image.per_image_standardization(distorted_image) \n",
    "\n",
    "        float_image.set_shape([height, width, 3])\n",
    "        read_input.label.set_shape([1])\n",
    "\n",
    "        min_fraction_of_examples_in_queue = 0.4\n",
    "        min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN * min_fraction_of_examples_in_queue)\n",
    "        print ('Filling queue with %d CIFAR images before starting to train. '\n",
    "             'This will take a few minutes.' % min_queue_examples)\n",
    "\n",
    "        return _generate_image_and_label_batch(float_image, read_input.label, min_queue_examples, batch_size, shuffle=True)\n",
    "\n",
    "def get_train():\n",
    "    return distorted_inputs(raw_img_dir, batch_size=128)\n",
    "\n",
    "def get_valid():\n",
    "    return distorted_inputs(raw_img_dir, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Model function:\n",
    "\n",
    "CONV1_SIZE = 5\n",
    "CONV1_FEATS = 32\n",
    "CONV2_SIZE = 5\n",
    "CONV2_FEATS = 32\n",
    "FC_SIZE = 200\n",
    "OUT_CLASSES = 10\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x, name):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=name)\n",
    "\n",
    "def weight_var(shape, name):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.get_variable(name=name, initializer=initial)\n",
    "\n",
    "def bias_var(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def model_fn(features, targets, mode, params):\n",
    "    \n",
    "    with tf.name_scope(\"MODEL_FUNCTION\"):\n",
    "        \n",
    "        ##############################\n",
    "        # First convolutional layer: #\n",
    "        ##############################\n",
    "\n",
    "        with tf.name_scope(\"Layer_1\"):\n",
    "            \n",
    "            W_conv1 = weight_var([CONV1_SIZE, CONV1_SIZE, 3, CONV1_FEATS], \"w1\")\n",
    "            b_conv1 = bias_var([CONV1_FEATS])\n",
    "            h_conv1 = tf.nn.relu(conv2d(features, W_conv1) + b_conv1)\n",
    "            h_pool1 = max_pool_2x2(h_conv1, \"hpool1\")\n",
    "\n",
    "        ###############################\n",
    "        # Second convolutional layer: #\n",
    "        ###############################\n",
    "\n",
    "        with tf.name_scope(\"Layer_2\"):\n",
    "            W_conv2 = weight_var([CONV2_SIZE, CONV2_SIZE, CONV1_FEATS, CONV2_FEATS], \"w2\")\n",
    "            b_conv2 = bias_var([CONV2_FEATS])\n",
    "            h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "            h_pool2 = max_pool_2x2(h_conv2, \"hpool2\")\n",
    "\n",
    "        ############################\n",
    "        # Densely connected layer: #\n",
    "        ############################\n",
    "\n",
    "        with tf.name_scope(\"Dense_1\"):\n",
    "\n",
    "            new_img_size = IMAGE_SIZE / 4\n",
    "            W_fc1 = weight_var([new_img_size * new_img_size * CONV2_FEATS, FC_SIZE], \"wfc1\")\n",
    "            b_fc1 = bias_var([FC_SIZE])\n",
    "\n",
    "            h_pool2_flat = tf.reshape(h_pool2, [-1, new_img_size * new_img_size * CONV2_FEATS])\n",
    "            h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "        ##################\n",
    "        # Dropout layer: #\n",
    "        ##################\n",
    "\n",
    "        with tf.name_scope(\"Dropout_layer\"):\n",
    "\n",
    "            keep_prob = params[\"dropout_keep_prob\"]\n",
    "            h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "        ##################\n",
    "        # Readout layer: #\n",
    "        ##################\n",
    "\n",
    "        with tf.name_scope(\"Readout_layer\"):\n",
    "\n",
    "            W_fc2 = weight_var([FC_SIZE, OUT_CLASSES], \"wfc2\")\n",
    "            b_fc2 = bias_var([OUT_CLASSES])\n",
    "\n",
    "            y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "            y_true = tf.one_hot(targets, OUT_CLASSES)\n",
    "\n",
    "        #########\n",
    "        # Loss: #\n",
    "        #########\n",
    "\n",
    "        with tf.name_scope(\"Loss\"):\n",
    "\n",
    "            # Cross-entropy loss:\n",
    "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_conv))\n",
    "\n",
    "        #############\n",
    "        # Accuracy: #\n",
    "        #############\n",
    "\n",
    "        pred_vals = tf.argmax(y_conv, 1)\n",
    "        correct_vals = tf.argmax(y_true, 1)\n",
    "        acc = tf.reduce_mean(tf.cast(tf.equal(pred_vals, correct_vals), tf.float64))\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"Train\"):\n",
    "\n",
    "            # Training subgraph:\n",
    "            global_step = tf.train.get_global_step()\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=params[\"learning_rate\"])\n",
    "            train = tf.group(optimizer.minimize(loss), tf.assign_add(global_step, 1))\n",
    "\n",
    "\n",
    "        ###############################\n",
    "        # Summaries and eval metrics: #\n",
    "        ###############################\n",
    "        with tf.name_scope('summaries'):\n",
    "            tf.summary.scalar(\"Loss\", loss)\n",
    "            tf.summary.scalar(\"Accuracy\", acc)\n",
    "        eval_metric_ops = {\n",
    "            \"Accuracy\": acc\n",
    "        }\n",
    "\n",
    "        # Return a \"ModelFnOps\" instance:\n",
    "        preds = {'y_conv': y_conv, 'h_pool1': h_pool1, 'h_pool2': h_pool2}\n",
    "        return tf.contrib.learn.ModelFnOps(mode=mode,\n",
    "                                           predictions=preds,\n",
    "                                           loss=loss,\n",
    "                                           train_op=train,\n",
    "                                           eval_metric_ops=eval_metric_ops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.contrib.learn as tflearn\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "import tensorflow.contrib.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./models/'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'conv1'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Clear model dir:\n",
    "#!rm -r $MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x113cd67d0>, '_model_dir': './models/conv1', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "WARNING:tensorflow:continuous_train_and_eval (from tensorflow.contrib.learn.python.learn.experiment) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO:tensorflow:Training model for 500 steps\n",
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./models/conv1/model.ckpt-2001\n",
      "INFO:tensorflow:Saving checkpoints for 2002 into ./models/conv1/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.00404, step = 2002\n",
      "INFO:tensorflow:global_step/sec: 4.85104\n",
      "INFO:tensorflow:loss = 1.02566, step = 2102 (20.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.76729\n",
      "INFO:tensorflow:loss = 1.06312, step = 2202 (20.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.69312\n",
      "INFO:tensorflow:loss = 1.24735, step = 2302 (21.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.90887\n",
      "INFO:tensorflow:loss = 1.12096, step = 2402 (20.371 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2501 into ./models/conv1/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.11651.\n",
      "INFO:tensorflow:Evaluating model now.\n",
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-20-03:27:34\n",
      "INFO:tensorflow:Restoring parameters from ./models/conv1/model.ckpt-2501\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-20-03:27:38\n",
      "INFO:tensorflow:Saving dict for global step 2501: Accuracy = 0.609375, global_step = 2501, loss = 1.0688\n",
      "INFO:tensorflow:Stop training model as max steps reached\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Train the estimator:\n",
    "tf.logging.set_verbosity(v=tf.logging.INFO)\n",
    "model_params = {\"learning_rate\": 0.0003, \"dropout_keep_prob\": 0.8}\n",
    "\n",
    "# Clear model dir:\n",
    "#!rm -r $MODEL_DIR\n",
    "\n",
    "model_dir = os.path.join(MODEL_DIR, MODEL_NAME)\n",
    "\n",
    "my_estimator = tf.contrib.learn.Estimator(model_fn=model_fn, params=model_params, model_dir=model_dir)\n",
    "#my_estimator.fit(input_fn=get_train, steps=5000)\n",
    "\n",
    "\n",
    "def experiment_fn(output_dir):\n",
    "    return tflearn.Experiment(\n",
    "        my_estimator,\n",
    "        train_input_fn=get_train,\n",
    "        eval_input_fn=get_valid,\n",
    "        train_steps=100,\n",
    "        eval_steps=10,\n",
    "        train_steps_per_iteration=500\n",
    "    )\n",
    "\n",
    "learn_runner.run(experiment_fn, output_dir=\"/tt/1\", schedule=\"continuous_train_and_eval\")\n",
    "\n",
    "print \"done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_config': <tensorflow.contrib.learn.python.learn.estimators.run_config.RunConfig at 0x113cd6850>,\n",
       " '_device_fn': None,\n",
       " '_feature_engineering_fn': <function tensorflow.contrib.learn.python.learn.estimators.estimator._identity_feature_engineering_fn>,\n",
       " '_features_info': TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(128), Dimension(32), Dimension(32), Dimension(3)]), is_sparse=False),\n",
       " '_graph': <tensorflow.python.framework.ops.Graph at 0x113cd6690>,\n",
       " '_labels_info': TensorSignature(dtype=tf.int32, shape=TensorShape([Dimension(128)]), is_sparse=False),\n",
       " '_model_dir': './models/conv1',\n",
       " '_model_fn': <function __main__.model_fn>,\n",
       " '_session_config': allow_soft_placement: true,\n",
       " 'params': {'dropout_keep_prob': 0.7, 'learning_rate': 0.001}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_estimator.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '\u0006'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-14c5d09b037e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-14c5d09b037e>\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '\u0006'."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "MODEL_PATH = \"./models/conv1\"\n",
    "IMAGE_PATH = \"./data/cifar-10-batches-bin/data_batch_1.bin\"\n",
    "\n",
    "def unpickle(file):\n",
    "    import cPickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = cPickle.load(fo)\n",
    "    return dict\n",
    "\n",
    "def reshape_img(img_arr):\n",
    "    # https://stackoverflow.com/questions/20341614/numpy-array-row-major-and-column-major\n",
    "    return img_arr.reshape([1024, 3], order='F').reshape([32, 32, 3]) / 255.\n",
    "\n",
    "def plot_img(img_arr):\n",
    "    plt.imshow(img_arr)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "tmp = unpickle(IMAGE_PATH)\n",
    "data, labels = tmp[\"data\"], tmp[\"labels\"]\n",
    "    \n",
    "img_index = 1 # Some random image\n",
    "img = reshape_img(data[img_index])\n",
    "    \n",
    "plot_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def single_img_fn():\n",
    "    return tf.cast(tf.expand_dims(tf.constant(img), 0), tf.float32)\n",
    "\n",
    "single_img_fn()\n",
    "\n",
    "x = list(my_estimator.predict(input_fn=single_img_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "prediction = x[0]['y_conv']\n",
    "hpool1 = x[0]['h_pool1']\n",
    "hpool2 = x[0]['h_pool2']\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"Shape:\", hpool1.shape\n",
    "for i in range(3):\n",
    "    grid = hpool1[:, :, i]\n",
    "    plt.imshow(grid)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"Shape:\", hpool2.shape\n",
    "#for i in range(hpool2.shape[2]):\n",
    "for i in range(3):    \n",
    "    grid = hpool2[:, :, i]\n",
    "    plt.imshow(grid)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
